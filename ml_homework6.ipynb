{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPU/V+sxAPQhhB6OrBtLyy5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aasyngier/machine-learning/blob/main/ml_homework6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Homework Assignment: Understanding Splitting Criteria in CART for Regression**\n",
        "---------------------\n",
        "\n",
        "In this assignment, you will explore three common formulations of the splitting criterion used in **CART (Classification and Regression Trees)** for **regression problems**:\n",
        "\n",
        "1. **Local RSS Minimization**  \n",
        "2. **RSS Gain Maximization**  \n",
        "3. **Total RSS Minimization**\n",
        "\n",
        "You will investigate whether any of these criteria are equivalent, and you will design an experiment to determine which criterion is actually employed in a standard implementation such as **scikit-learn’s DecisionTreeRegressor**.\n",
        "\n",
        "\n",
        "\n",
        "## **The Problem**\n",
        "\n",
        "Many treatments of CART for regression describe the split selection process in different ways. Below are three frequently cited formulations. Suppose we have a dataset with features $X$ and target $y$, and we seek to choose a feature $X_j$ and a threshold $t$ to split the data into two regions $R_1(X_j, t)$ and $R_2(X_j, t)$. Denote by $\\bar{y}_{R_m}$ the mean of targets within region $R_m$.\n",
        "\n",
        "1. **Local RSS Minimization**  \n",
        "   We select the feature and threshold that minimize the **sum of squared errors** in the two resulting child nodes:\n",
        "   $$\n",
        "   (X_j^*, t^*) = \\arg\\min_{X_j, t} \\sum_{m=1}^{2} \\sum_{i : x_i \\in R_m(X_j, t)} (y_i - \\bar{y}_{R_m})^2.\n",
        "   $$\n",
        "\n",
        "2. **RSS Gain Maximization**  \n",
        "\n",
        "   It is also a local method, looking only at a parent and two child nodes.\n",
        "\n",
        "   We select the feature and threshold that maximize the **reduction** in RSS, computed by subtracting the RSS of the two child nodes from the RSS in the parent node:\n",
        "   $$\n",
        "   (X_j^*, t^*) = \\arg\\max_{X_j, t} \\Bigl\\{\n",
        "   \\underbrace{\\sum_{i : x_i \\in \\text{Parent}} (y_i - \\bar{y})^2}_{\\text{Parent RSS}}\n",
        "   \\;-\\;\n",
        "   \\underbrace{\\sum_{m=1}^{2} \\sum_{i : x_i \\in R_m(X_j, t)} (y_i - \\bar{y}_{R_m})^2}_{\\text{Children RSS}}\n",
        "   \\Bigr\\}.\n",
        "   $$\n",
        "\n",
        "3. **Total RSS Minimization**  \n",
        "   For a dataset $\\{(x_i, y_i)\\}_{i=1}^N$ with features $X$ and target $y$, let $T$ be the current tree.\n",
        "\n",
        "   For any split on feature $X_j$ at threshold $t$, define $T(X_j, t)$ as the new tree obtained by splitting one leaf of $T$ into two leaves $R_1(X_j, t)$ and $R_2(X_j, t)$.\n",
        "   \n",
        "   Let $\\mathrm{Leaves}(T(X_j, t))$ be the set of all leaf indices in this new tree. For each leaf $m \\in \\mathrm{Leaves}(T(X_j, t))$, define:\n",
        "   $$\n",
        "   R_m = \\{\\, i \\,\\mid\\, x_i \\text{ ends in leaf } m\\}.\n",
        "   $$\n",
        "\n",
        "   $R_m$ set collects all data indices $i$ whose feature vector $x_i$ is classified into the leaf node $m$ when passed through the tree $T(X_j,t)$. In other words, each leaf node $m$ in $T(X_j, t)$ corresponds to a unique path of splits, and any data point $x_i$ that follows that path is assigned to the leaf $m$; hence, it belongs to $R_m$.\n",
        "\n",
        "   $R_m$ sets for all leafs $m \\in \\mathrm{Leaves}(T(X_j, t))$ define a partition of all indices.\n",
        "\n",
        "   Then the objective of **minimizing total Residual Sum of Squares (total RSS)** is stated as:\n",
        "   $$\n",
        "   (X_j^*, t^*) = \\arg\\min_{(X_j, t)} \\sum_{m \\in \\mathrm{Leaves}(T(X_j, t))}\n",
        "   \\sum_{i \\in R_m} \\Bigl(y_i - \\overline{y}_{R_m}\\Bigr)^2,\n",
        "   $$\n",
        "   where\n",
        "   $$\n",
        "   \\overline{y}_{R_m} = \\frac{1}{\\lvert R_m \\rvert}\n",
        "   \\sum_{i \\in R_m} y_i\n",
        "   $$\n",
        "   is the mean response in leaf $m$.\n",
        "\n",
        "\n",
        "## **Research Questions**\n",
        "\n",
        "1. **Equivalence Analysis**  \n",
        "   Determine whether the above formulations are equivalent or if they can yield different split choices. Specifically:\n",
        "   - Are *local RSS minimization* and *RSS gain maximization* equivalent?\n",
        "   - Does *total RSS minimization* coincide with either of these two, or is it distinct?\n",
        "   \n",
        "2. **Empirical Experiment**  \n",
        "   Design and conduct a Python experiment to determine which of these formulations is implemented in `scikit-learn` in `DecisionTreeRegressor`. Present numerical results and plots to support your conclusion.\n",
        "\n",
        "## **Tasks & Deliverables**\n",
        "\n",
        "1. **Formulation Analysis**  \n",
        "   - Compare *local RSS minimization*, *RSS gain maximization*, and *total RSS minimization*.\n",
        "   - If you find that any pair of formulations is equivalent, provide a concise proof.  \n",
        "   - If you find that they differ, construct a counterexample.\n",
        "\n",
        "2. **Empirical Verification**  \n",
        "   - Create a small artificial dataset and train a `DecisionTreeRegressor` from `scikit-learn`.\n",
        "   - The dataset must be designed in a way that uniquely identifies the formulation used. Provide a short code snippet and a plot or table to support your conclusion.\n",
        "\n",
        "3. **Report**  \n",
        "   - Summarize your theoretical insights and empirical findings in a **Colab notebook**.\n",
        "   - Include the relevant proofs, code, discussion, and conclusions.\n",
        "   - Place the notebook in your **GitHub repository** for this course, add a link to it in your README.md and add an **“Open in Colab”** badge in the notebook so it can be launched directly.\n"
      ],
      "metadata": {
        "id": "NIY2ZIxAnpaY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Equivalence analysis of local RSS minimization and RSS gain maximization\n",
        "\n",
        "Notice that RSS gain maximization can be presented in the following way\n",
        "$$\n",
        "\\mathrm{RSS}_{\\rm parent}\n",
        "- \\sum_{m=1}^2\\sum_{i\\in R_m}(y_i - \\bar y_{R_m})^2\n",
        "\\;=\\;\n",
        "\\;\\underbrace{\\mathrm{const}}_{\\text{independent of }X_j, t}-\\;\n",
        "\\underbrace{\\Bigl(\n",
        "      \\sum_{m=1}^2\\sum_{i\\in R_m}\n",
        "      (y_i-\\bar y_{R_m})^2\n",
        "     \\Bigr)}_{\\text{Children RSS}}\n",
        "$$\n",
        "\n",
        "Thus we have\n",
        "\n",
        "$$\n",
        "\\arg\\min_{X_j,t}\\sum_{m=1}^{2}\\sum_{i\\in R_m}\\bigl(y_i-\\bar{y}_{R_m}\\bigr)^{2}\n",
        "\\;=\\;\n",
        "\\arg\\max_{X_j,t}\\Bigl\\{\\mathrm{RSS}_{\\text{parent}}\n",
        "      -\\sum_{m=1}^{2}\\sum_{i\\in R_m}\\bigl(y_i-\\bar{y}_{R_m}\\bigr)^{2}\\Bigr\\}\n",
        "$$\n",
        "\n",
        "\n",
        "And hence\n",
        "\n",
        "$$\n",
        "\\text{Local RSS minimization}\\;\\iff\\;\\text{RSS gain maximization.}\n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "id": "zTktR7S1qjEv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Equivalence analysis of total RSS minimization and either of the two above\n",
        "\n",
        "At first glance it may seem that these methods yield different results. However let's take a closer look at what is happening as we split a specific leaf of our current tree, $T$ with a leaf set, $\\mathrm{Leaves}(T)$.\n",
        "\n",
        "Suppose we split exactly one leaf $m_0\\in\\mathrm{Leaves}(T)$ by feature $X_j$ at threshold $t$, producing two new leaves $m_1,m_2$, while every other leaf remains unchanged.  Denote by $T(j,t)$ the resulting tree, and by $R_m$ the index‐set of points falling in leaf $m$.\n",
        "\n",
        "Then the total RSS of $T(j,t)$ can be written as\n",
        "\n",
        "$$\n",
        "\\sum_{m\\in\\mathrm{Leaves}(T(j,t))}\\sum_{i\\in R_m}\\bigl(y_i-\\bar y_{R_m}\\bigr)^2\n",
        "=\n",
        "\\underbrace{\\sum_{\\substack{m\\in\\mathrm{Leaves}(T)\\\\m\\neq m_0}}\n",
        "\\sum_{i\\in R_m}\\bigl(y_i-\\bar y_{R_m}\\bigr)^2}_{\\text{independent of }X_j, t}\n",
        "\\;+\\;\n",
        "\\sum_{m\\in\\{m_1,m_2\\}}\\sum_{i\\in R_m}\\bigl(y_i-\\bar y_{R_m}\\bigr)^2\n",
        "$$\n",
        "\n",
        "Since the first term does not depend on our choice of $X_j$ and $t$, minimizing the total RSS is equivalent to minimizing only the new leaves’ RSS:\n",
        "\n",
        "$$\n",
        "\\arg\\min_{X_j,t}\\;\\sum_{m\\in\\mathrm{Leaves}(T(j,t))}\\sum_{i\\in R_m}(y_i-\\bar y_{R_m})^2\n",
        "\\;=\\;\n",
        "\\arg\\min_{X_j,t}\\;\\sum_{m\\in\\{m_1,m_2\\}}\\sum_{i\\in R_m}(y_i-\\bar y_{R_m})^2\n",
        "$$\n",
        "\n",
        "And since the right‐hand side is exactly the local RSS objective, we obtain\n",
        "\n",
        "$$\n",
        "\\text{Total RSS minimization}\n",
        "\\;\\iff\\;\n",
        "\\text{Local RSS minimization}\n",
        "\\;\\iff\\;\n",
        "\\text{RSS gain maximization}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "yg9uM9rWsHs4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. What if we attempt to pre-prun the tree and add conditions when training?\n",
        "\n",
        "In both of the cases above we concluded that all three of the methods are equivalent when we don't impose any constraints during the training process. Let's explore if it changes when we try to pre-prun our tree.\n",
        "  \n",
        "#### Why pre‐pruning breaks global/local equivalence:\n",
        "\n",
        "When you constrain the depth/ total number of leaves, the global total‐RSS objective would pick the sequence of splits that minimizes RSS across the entire final tree. On the other hand, a greedy local‐gain algorithm always picks the single next split that yields the largest immediate RSS reduction, then stops as soon as the depth/ leaf limit is reached."
      ],
      "metadata": {
        "id": "9PrbZctDyTfZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Empirical Experiment\n",
        "\n",
        "Let's now conduct a Python experiment to determine which of these formulations is implemented in scikit-learn in DecisionTreeRegressor. To observe the result we'll use pre-pruning: in our case let's impose a constraint on max_leaf_nodes $= 3$.\n"
      ],
      "metadata": {
        "id": "Dcb8Dlp3Be57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our synthetic data:  "
      ],
      "metadata": {
        "id": "qpdl_SAP0eym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.arange(10).reshape(-1,1)\n",
        "y = np.array([0,0,0,0,0,55,153,270,478,469], dtype=float)"
      ],
      "metadata": {
        "id": "9efn-S-r0hho"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| root_t | gain_root    | best_second_gain | total_gain_two_splits |\n",
        "|-------:|-------------:|-----------------:|-------------------:|\n",
        "|   5.5  |   266666.6667|          68644.0 |        335310.6667 |\n",
        "|   6.5  |   296814.4048|          27608.1667|       324422.5714 |\n"
      ],
      "metadata": {
        "id": "17uKs20I1gLg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Local best (largest gain_root) is at $t=6.5$\n",
        "- Global best (largest total_gain_two_splits) is at $t=5.5$\n",
        "\n",
        "We now check which one of them the scikit‑learn tree picks as its first split."
      ],
      "metadata": {
        "id": "CRQ6xehMz0aZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree = DecisionTreeRegressor(max_leaf_nodes=3, random_state=0)\n",
        "tree.fit(X, y)\n",
        "print(\"Chosen root threshold:\", tree.tree_.threshold[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NK_F45YfztXB",
        "outputId": "51979a0a-bee4-444a-d7b9-93dfe47e06cc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen root threshold: 6.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hence our empirical experiment confirms that even under pre‑pruning, scikit‑learn’s tree uses the greedy, local per‑node RSS‑gain criterion rather than optimizing the total RSS across all leaves."
      ],
      "metadata": {
        "id": "Tpk2ISt17NvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "t_chosen = tree.tree_.threshold[0]\n",
        "plt.figure()\n",
        "plt.scatter(X, y, s=80)\n",
        "plt.axvline(t_chosen, linestyle='--')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Root split with max_leaf_nodes=3')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "--ulU_-_0lsL",
        "outputId": "8dfade71-81ee-4938-c86f-641ff2dfed6c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the computation for the table presented earlier, comparing gains for the both thresholds:"
      ],
      "metadata": {
        "id": "bDT3btvd8jgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def rss(arr):\n",
        "    return ((arr - arr.mean())**2).sum()\n",
        "\n",
        "parent = rss(y)\n",
        "thresholds = [5.5, 6.5]\n",
        "rows = []\n",
        "\n",
        "for t in thresholds:\n",
        "    left  = y[X.ravel() <=  t]\n",
        "    right = y[X.ravel() >   t]\n",
        "    gain_root = parent - (rss(left) + rss(right))\n",
        "\n",
        "    best_second = 0\n",
        "    for arr, pos in [(left,  X.ravel()[X.ravel() <=  t]),\n",
        "                     (right, X.ravel()[X.ravel() >   t])]:\n",
        "        if len(arr) < 2: continue\n",
        "        order = np.argsort(pos)\n",
        "        pos_s  = pos[order]\n",
        "        arr_s  = arr[order]\n",
        "        mids   = [(pos_s[i] + pos_s[i+1])/2 for i in range(len(pos_s)-1)]\n",
        "        for m in mids:\n",
        "            l2 = arr_s[pos_s <= m]\n",
        "            r2 = arr_s[pos_s >  m]\n",
        "            if len(l2) and len(r2):\n",
        "                gain2 = rss(arr_s) - (rss(l2) + rss(r2))\n",
        "                best_second = max(best_second, gain2)\n",
        "\n",
        "    total_gain = gain_root + best_second\n",
        "    rows.append({\n",
        "        'root_t':            t,\n",
        "        'gain_root':         gain_root,\n",
        "        'best_second_gain':  best_second,\n",
        "        'total_gain_two_splits': total_gain\n",
        "    })\n",
        "\n",
        "pd.DataFrame(rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "YvRBZV__6vy2",
        "outputId": "2c5491ef-4561-40ee-f17e-0a40fd3edda7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   root_t      gain_root  best_second_gain  total_gain_two_splits\n",
              "0     5.5  266666.666667      68644.000000          335310.666667\n",
              "1     6.5  296814.404762      27608.166667          324422.571429"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b4693741-b92a-41f0-9e57-50c78bad68c9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>root_t</th>\n",
              "      <th>gain_root</th>\n",
              "      <th>best_second_gain</th>\n",
              "      <th>total_gain_two_splits</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.5</td>\n",
              "      <td>266666.666667</td>\n",
              "      <td>68644.000000</td>\n",
              "      <td>335310.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.5</td>\n",
              "      <td>296814.404762</td>\n",
              "      <td>27608.166667</td>\n",
              "      <td>324422.571429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4693741-b92a-41f0-9e57-50c78bad68c9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b4693741-b92a-41f0-9e57-50c78bad68c9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b4693741-b92a-41f0-9e57-50c78bad68c9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7298cde5-b4f2-41ca-81bb-ffed13a150ff\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7298cde5-b4f2-41ca-81bb-ffed13a150ff')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7298cde5-b4f2-41ca-81bb-ffed13a150ff button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"root_t\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7071067811865476,\n        \"min\": 5.5,\n        \"max\": 6.5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          6.5,\n          5.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gain_root\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21317.670044578834,\n        \"min\": 266666.6666666667,\n        \"max\": 296814.40476190473,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          296814.40476190473,\n          266666.6666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"best_second_gain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29016.71602164097,\n        \"min\": 27608.166666666668,\n        \"max\": 68644.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          27608.166666666668,\n          68644.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_gain_two_splits\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7699.045977062119,\n        \"min\": 324422.5714285714,\n        \"max\": 335310.6666666667,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          324422.5714285714,\n          335310.6666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}